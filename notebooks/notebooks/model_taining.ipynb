{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and clear GPU cache\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from pytorch_lightning import seed_everything\n",
    "from tqdm import tqdm\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "import torchmetrics\n",
    "from torchmetrics.functional.classification import binary_accuracy, binary_f1_score, binary_precision, binary_recall, binary_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU cache and check GPU usage\n",
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tokenizers parallelism to avoid warning messages\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for available GPU and set the device\n",
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset\n",
    "train = pd.read_csv('#') # Path to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and validation sets\n",
    "train_data, val_data = train_test_split(train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 2e-5\n",
    "max_length = 512\n",
    "batch_size = 8\n",
    "num_labels = 2\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer and pretrained model\n",
    "model_ckp = '#' # Model checkpoint: microsoft/Multilingual-MiniLM-L12-H384\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckp)\n",
    "pretrained_model = AutoModelForSequenceClassification.from_pretrained(model_ckp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dataset class\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data.iloc[index]['#'] # Column name for the text data\n",
    "        label = self.data.iloc[index]['#'] # Column name for the label data\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text, \n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt')\n",
    "        return encoding['input_ids'][0], encoding['attention_mask'][0], label.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation datasets and data loaders\n",
    "train_dataset = MyDataset(train_data, tokenizer, max_length)\n",
    "val_dataset = MyDataset(val_data, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model class\n",
    "class MyModel(pl.LightningModule):\n",
    "    def __init__(self, num_labels, batch_size, learning_rate):\n",
    "        super().__init__()\n",
    "        self.model = pretrained_model\n",
    "        self.num_classes = num_labels\n",
    "        self.loss_function = loss_fn\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "           \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return outputs.logits\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, drop_last=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False, num_workers=2, drop_last=True)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, label = batch\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        loss = self.loss_function(outputs, label)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        accuracy = binary_accuracy(preds, label)\n",
    "        f1_score = binary_f1_score(preds, label)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"train_accuracy\", accuracy, prog_bar=True, logger=True)\n",
    "        self.log(\"train_f1\", f1_score, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, label = batch\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        loss = self.loss_function(outputs, label)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        accuracy = binary_accuracy(preds, label)\n",
    "        f1_score = binary_f1_score(preds, label)\n",
    "        recall = binary_recall(preds, label)\n",
    "        precision = binary_precision(preds, label)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"val_accuracy\", accuracy, prog_bar=True, logger=True)\n",
    "        self.log(\"val_f1\", f1_score, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, label = batch\n",
    "        outputs = self(input_ids, attention_mask)\n",
    "        loss = self.loss_function(outputs, label)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        accuracy = binary_accuracy(preds, label)\n",
    "        f1_score = binary_f1_score(preds, label)\n",
    "        recall = binary_recall(preds, label)\n",
    "        precision = binary_precision(preds, label)\n",
    "        confusion_matrix = binary_confusion_matrix(preds, label).cpu().detach().numpy()\n",
    "        df_cm = pd.DataFrame(confusion_matrix, index=range(2), columns=range(2))\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        fig_ = sns.heatmap(df_cm, annot=True, cmap='Spectral').get_figure()\n",
    "        plt.close(fig_)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
    "        self.log(\"test_accuracy\", accuracy, prog_bar=True, logger=True)\n",
    "        self.log(\"test_f1\", f1_score, prog_bar=True, logger=True)\n",
    "        self.logger.experiment.add_figure('confusion matrix', fig_, global_step=self.current_epoch)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': lr_scheduler,\n",
    "            'monitor': 'val_loss'\n",
    "        }\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "seed_everything(42, workers=True)\n",
    "\n",
    "# Initialize the model\n",
    "model = MyModel(num_labels, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure model checkpoint callback\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='./best_model/',\n",
    "    filename='best_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PyTorch Lightning trainer\n",
    "trainer = pl.Trainer(max_epochs=epochs, gpus=1, \n",
    "                     callbacks=[checkpoint_callback, TQDMProgressBar(refresh_rate=5)], deterministic=True)\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, model.train_dataloader(), model.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate the model\n",
    "trainer.validate(model, model.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model checkpoint for testing\n",
    "best_model = MyModel.load_from_checkpoint(checkpoint_callback.best_model_path, num_labels=num_labels, batch_size=batch_size, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test datasets\n",
    "test01 = pd.read_csv('#') # Path to the test dataset\n",
    "test02 = pd.read_csv('#') # Path to the test dataset\n",
    "test03 = pd.read_csv('#') # Path to the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on test datasets\n",
    "for i, test_data in enumerate([test01, test02, test03], start=1):\n",
    "    test_dataset = MyDataset(test_data, tokenizer, max_length)\n",
    "    best_model = MyModel.load_from_checkpoint(\n",
    "        checkpoint_callback.best_model_path,\n",
    "        num_labels=num_labels,\n",
    "        batch_size=batch_size,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    print(f\"Testing on Dataset {i}...\")\n",
    "    trainer.test(best_model, DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wahid_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
